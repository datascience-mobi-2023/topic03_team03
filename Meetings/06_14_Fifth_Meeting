Fragen:
1. Ergibt es Sinn wie wir die Gene rausgeworfen und dann die Mittelwerte berechnet haben?
2. Welche Clustering-Methode? (kmeans ist ein terafail)
3. Optional: Wie führt man diese Clustering-Methode durch?
4. Auf welche Variable sollen wir den t-Test anwenden? Ergibt mu als Varible Sinn?
5. Ist der Threshhold für unsere RDPs so gut gesetzt? Es fliegen halt bei 5% sehr viele Proteine raus.
6. Wie greifen wir auf die Datenbanken zurück?
7. Wie genau soll das Markdown aufgebaut sein?

Antworten:
1. solange wir nicht alle 3 Replikate brauchen, können alle Schritte für alle Proteine durchgeführt werden und dann nur aus dem Endergebniss genommen werden, dann müssen Proteine nicht gestrichen werden

2. kmeans mit anderen Datenpunkten -- welchen? - partial shift, no shift, complete shifter 2 Variablen: Entfernung in Fraktion & unterschiedlicher Protein amount => Vergleich von Proteinamount in bestimmter Fraktion, Vergleich von RNAse und Control
  - hierarchisches Cluster
  - DV Scan, keine Punkte, sondern basierend darauf, wie dicht Datenpunkte liegen werden die Cluster bestimmt
  - Maiwens Abbildung kein Clustering, sondern Kategorien vorher rechnerisch erstellt
  
3. --

4. einfach irgendwo einbauen... ("t-test relativ latte")
- wie gut passt Gaußkurve auf Ursprungsdaten
- ob shift stattfindet => Proteinamounts (2 unterschiedliche max peaks in unterschiedlichen Fraktionen => testet ob partial shift, no shift ...)

5. einfach weiterrechnen
- wie generiert man Sinnvolle selection criteria
- hight shift kann weniger Streng sein, kann weniger als 3 sein
- Overlap Kriterium passt so ("ah ne, das fine")
- wenige RBPs ist nicht Schlimm

6. keine Packages oder so, um auf Datenbanken zuzugreifen
- API berechnen
- RDeep und RBP2go: können alle Datensätze runtergeladen werden zum Vergleich, alle Proteine haben selben entry name

7. Markdown
- Material and Methods
keine Plots
nur Vorgehensweise, keine Ergebnisse
in Teilen Chunks
- Results:
nach Cleanup sehen Daten so aus
nach Gauß so
- Discussion besonders wichtig
- 2 Proteine reichen zur Darstellung aus (möglichst diverse Proteine nehmen (bspw. CTCF_HUMAN)) (no overly fancy plots)

Letzte Woche: 
  - keine Alternative zu optimize (einzige Idee: parallel laufen zu lassen (library "parallel"))
  - Berechnung des overlaps bei den Gaußkurven: library "uniroot" -> Schnittpunkte und dann Integrale berechnen
  - Zeitmessung in Chunks: "microbenchmark" (schaut, wie effizient eine Funktion läuft) 
  
---> Übernächste Woche Tut (wegen Biochemie-Praktikum): eventuell donnerstags online nach Klausur?


